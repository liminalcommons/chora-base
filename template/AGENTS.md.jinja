# AGENTS.md

This file provides machine-readable instructions for AI coding agents working with {{ project_name }}.

---

## Project Overview

**{{ project_name }}** is {% if project_type == 'mcp_server' %}a Model Context Protocol (MCP) server that provides [describe your server's capabilities]{% elif project_type == 'library' %}a Python library that [describe your library's purpose]{% elif project_type == 'cli_tool' %}a command-line tool that [describe what your tool does]{% elif project_type == 'web_service' %}a web service/API that [describe your service]{% endif %}.

{% if project_type == 'mcp_server' -%}
**Core Architecture:** [Describe your architecture pattern]
- [Key architecture point 1]
- [Key architecture point 2]
- [Key architecture point 3]

**Key Components:**
- **Main Module** (`[main_module].py`) - [Description]
- **[Component 2]** (`[module].py`) - [Description]
- **[Component 3]** (`[module].py`) - [Description]

{% endif -%}

{% if include_vision_docs -%}
### Strategic Context

**Current Priority:** [Describe current sprint/milestone focus]
- See [ROADMAP.md](ROADMAP.md) for committed work
- Focus: [List 2-3 key deliverables]

**Long-Term Vision:** [Describe evolutionary direction]
- See [dev-docs/vision/](dev-docs/vision/) for future capabilities
- Waves: [List 2-4 high-level capability themes]

**Design Principle:** Deliver current commitments while keeping future doors open.
- Don't build future features now
- Do design extension points and document decisions
- Do refactor when it serves both present and future

{% endif -%}
---

## Documentation Structure (Nearest File Wins)

**{{ project_name }} uses nested AGENTS.md files** for focused, topic-specific guidance.

**Discovery principle**: Agents should read the AGENTS.md file nearest to the code they're working on.

### Available Guides

- **[AGENTS.md](AGENTS.md)** (this file) - Project overview, architecture, PR workflow, common tasks
{% if include_tests -%}
- **[tests/AGENTS.md](tests/AGENTS.md)** - Testing guide (run tests, coverage, linting, troubleshooting)
{% endif -%}
{% if include_memory_system -%}
- **[.chora/memory/AGENTS.md](.chora/memory/AGENTS.md)** - Memory system (event log, knowledge graph, A-MEM workflows)
{% endif -%}
{% if include_docker -%}
- **[docker/AGENTS.md](docker/AGENTS.md)** - Docker operations (build, deploy, troubleshooting)
{% endif -%}
- **[scripts/AGENTS.md](scripts/AGENTS.md)** - Automation scripts reference

**When to use which guide:**

| Working on... | Read... |
|---------------|---------|
| Writing/running tests | [tests/AGENTS.md](tests/AGENTS.md) |
| Cross-session learning, memory queries | [.chora/memory/AGENTS.md](.chora/memory/AGENTS.md) |
| Docker builds, container deployment | [docker/AGENTS.md](docker/AGENTS.md) |
| Automation scripts, justfile tasks | [scripts/AGENTS.md](scripts/AGENTS.md) |
| Architecture, PRs, project structure | [AGENTS.md](AGENTS.md) (this file) |

---

## Dev Environment Tips

### Prerequisites
- **Python {{ python_version }}+** required ({{ python_version }}+ recommended)
- **Git** for version control
{% if include_justfile -%}
- **just** (optional but recommended) - Task runner for common commands
{% endif -%}
- **[Add project-specific prerequisites]**

### Installation

```bash
# Clone repository
git clone https://github.com/{{ github_username }}/{{ project_slug }}.git
cd {{ project_slug }}

# One-command setup (recommended)
./scripts/setup.sh

# Manual setup alternative
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -e ".[dev]"
{% if include_pre_commit -%}
pre-commit install
{% endif -%}
```

### Environment Variables

Create a `.env` file in project root:

```env
# Application configuration
{{ package_name | upper }}_LOG_LEVEL=INFO     # DEBUG, INFO, WARNING, ERROR, CRITICAL
{{ package_name | upper }}_DEBUG=0             # Set to 1 for debug mode

# Add your environment variables here
```

{% if project_type == 'mcp_server' -%}
### Client Configuration

#### Claude Desktop (macOS)

**Development Mode (Editable Install):**
```json
{
  "mcpServers": {
    "{{ project_slug }}-dev": {
      "command": "/path/to/{{ project_slug }}/.venv/bin/python",
      "args": ["-m", "{{ package_name }}.server"],
      "cwd": "/path/to/{{ project_slug }}",
      "env": {
        "{{ package_name | upper }}_DEBUG": "1"
      }
    }
  }
}
```

**Production Mode (Installed Package):**
```json
{
  "mcpServers": {
    "{{ project_slug }}": {
      "command": "{{ project_slug }}",
      "args": [],
      "env": {}
    }
  }
}
```

**Config file location:** `~/Library/Application Support/Claude/claude_desktop_config.json`

#### Cursor

See `.config/cursor-mcp.example.json` for complete examples.

**Config file location:** `~/.cursor/mcp.json`

{% endif -%}
---

{% if include_api_utilities or include_persistence_helpers -%}
## Python Utilities (Optional Ergonomics)

This project includes reusable utilities that implement proven patterns from production Python projects. These are **optional affordances** ‚Äî you can use them where helpful or ignore them.

### Available Utilities

{% if include_api_utilities -%}
| Utility | Purpose | Example Use |
|---------|---------|-------------|
| **validation.py** | Input normalization (dict/JSON/KV) | `@normalize_input(params=InputFormat.DICT_OR_JSON)` |
| **responses.py** | Response standardization | `Response.success(action="created", data=server)` |
| **errors.py** | Error formatting with suggestions | `ErrorFormatter.not_found("server", id, available)` |
{% endif -%}
{% if include_persistence_helpers -%}
| **persistence.py** | State persistence (atomic writes) | `class MyApp(StatefulObject): ...` |
{% endif -%}

### When to Use

**‚úÖ Use when:**
- Building user-facing APIs or CLIs
- Need consistent response/error formats
- Want to reduce boilerplate code
{% if include_persistence_helpers -%}
- Need crash-safe state persistence
{% endif -%}

**‚ö†Ô∏è Skip when:**
- Building simple internal functions
- Framework provides equivalent (FastAPI, Click decorators)
- Prototyping (can add later)

### Quick Examples

{% if include_api_utilities -%}
**Input Validation:**
```python
from {{ package_name }}.utils.validation import normalize_input, InputFormat
from {{ package_name }}.utils.responses import Response

@normalize_input(params=InputFormat.DICT_OR_JSON)
def create_resource(name: str, params: dict | None = None):
    # params accepts: {"key": "value"} OR '{"key": "value"}'
    # Auto-converted to dict
    return Response.success(action="created", data={"name": name})
```

**Error Formatting:**
```python
from {{ package_name }}.utils.errors import ErrorFormatter

def get_server(server_id: str):
    if server_id not in servers:
        error_msg = ErrorFormatter.not_found(
            entity_type="server",
            entity_id=server_id,
            available=list(servers.keys()),
        )
        return Response.error(error_code="not_found", message=error_msg)
```
{% endif -%}

{% if include_persistence_helpers -%}
**State Persistence:**
```python
from {{ package_name }}.utils.persistence import StatefulObject

class ConfigManager(StatefulObject):
    def __init__(self):
        super().__init__(state_file="~/.{{ package_name }}/config.json")
        self.config = getattr(self, 'config', {})  # Restored or default

    def update(self, settings: dict):
        self.config.update(settings)
        self._save_state()  # Atomic write
```
{% endif -%}

### Documentation

- **Reference Guide:** [user-docs/reference/python-patterns.md](user-docs/reference/python-patterns.md)
  - Complete API reference for all utilities
  - When to use each pattern
  - Performance and security considerations

- **How-To Guides:**
{% if include_api_utilities -%}
  - [How-To: Use Input Validation](user-docs/how-to/use-input-validation.md)
  - [How-To: Standardize Responses](user-docs/how-to/standardize-responses.md)
  - [How-To: Improve Error Messages](user-docs/how-to/improve-error-messages.md)
{% endif -%}
{% if include_persistence_helpers -%}
  - [How-To: Persist Application State](user-docs/how-to/persist-application-state.md)
{% endif -%}

### Benefits

**Code Reduction:**
{% if include_api_utilities -%}
- Input parsing: ~90% less boilerplate (20 lines ‚Üí 1 decorator)
- Response building: ~80-85% reduction (10-15 lines ‚Üí 2-3 lines)
{% endif -%}
{% if include_persistence_helpers -%}
- State persistence: ~70-75% reduction (25-30 lines ‚Üí 7-8 lines)
- Bonus: Atomic writes prevent corruption (would add ~15 lines manually)
{% endif -%}

**Quality:**
{% if include_api_utilities -%}
- Consistent API responses across all endpoints
- Helpful error messages with fuzzy matching suggestions
{% endif -%}
{% if include_persistence_helpers -%}
- Crash-safe persistence (atomic writes with fsync)
{% endif -%}

### Implementation Notes

**All utilities:**
- Use Python stdlib only (no external dependencies)
- Work with both sync and async functions
- Include comprehensive test suites (90%+ coverage)
- Follow type hints for IDE support

{% if include_api_utilities -%}
**Performance:**
- Input validation: <1ms overhead (JSON parsing main cost)
- Response building: Negligible (dict construction)
- Error formatting: <1ms for fuzzy matching (<1000 items)
{% endif -%}

{% if include_persistence_helpers -%}
**Persistence:**
- Atomic writes add ~5-10ms latency (ensures durability)
- Keep state files <1MB for best performance
- JSON-only (use encryption for sensitive data)
{% endif -%}

---

{% endif -%}
## PR Instructions

### Branch Naming

```
feature/descriptive-name     # New features
fix/issue-description        # Bug fixes
hotfix/critical-fix          # Production hotfixes
docs/documentation-update    # Documentation only
refactor/code-improvement    # Refactoring
```

### Commit Message Format

Follow **Conventional Commits** style:

```
type(scope): brief description

Detailed explanation of changes (if needed)

Closes #issue-number
```

**Types:** `feat`, `fix`, `docs`, `refactor`, `test`, `chore`, `perf`

**Scopes:** [List your project-specific scopes]

**Examples:**
```
feat(core): add new feature X

Implement feature X with comprehensive error handling
and unit tests.

Closes #23

---

fix(server): handle edge case gracefully

When [condition], system now [behavior] instead of
crashing.

Fixes #45
```

### PR Checklist

**Before opening PR:**
- [ ] Branch is up to date with `main`
{% if include_tests -%}
- [ ] All tests pass locally (`{% if include_justfile %}just test{% else %}pytest{% endif %}`)
- [ ] Coverage maintained or improved (‚â•{{ test_coverage_threshold }}%)
{% endif -%}
{% if include_pre_commit -%}
- [ ] Linting passes (`{% if include_justfile %}just lint{% else %}ruff check{% endif %}`)
- [ ] Type checking passes (`{% if include_justfile %}just typecheck{% else %}mypy src/{% endif %}`)
- [ ] Pre-commit hooks pass (`{% if include_justfile %}just pre-commit{% else %}pre-commit run --all-files{% endif %}`)
- [ ] Code formatted (`{% if include_justfile %}just format{% else %}ruff format{% endif %}`)
{% endif -%}

**Documentation (if applicable):**
- [ ] README.md updated (if user-facing changes)
{% if include_agents_md -%}
- [ ] AGENTS.md updated (if agent workflow changes)
{% endif -%}
- [ ] API reference docs updated (if new tools/capabilities)
- [ ] CHANGELOG.md entry added (for releases)

**Testing:**
{% if include_tests -%}
- [ ] Unit tests added/updated
- [ ] Integration tests added (if applicable)
- [ ] Smoke tests pass (`{% if include_justfile %}just smoke{% else %}pytest tests/smoke/{% endif %}`)
{% endif -%}
- [ ] Manual testing completed

**Review:**
- [ ] Self-review completed
- [ ] Code follows project style guide
- [ ] No debug code or commented-out code
- [ ] Error messages are clear and actionable
- [ ] Logging statements use appropriate levels

{% if include_pre_commit -%}
### Quality Gates (must pass)

1. **Lint:** `ruff check` ‚Üí No errors
2. **Format:** `ruff format --check` ‚Üí Formatted
3. **Types:** `mypy` ‚Üí Type safe
{% if include_tests -%}
4. **Tests:** All tests pass
5. **Coverage:** ‚â•{{ test_coverage_threshold }}%
{% endif -%}
6. **Pre-commit:** All hooks pass

{% endif -%}
### PR Review Process

- **Required approvals:** 1+ reviewer
- **Merge strategy:** Squash and merge (clean history)
{% if include_github_actions -%}
- **CI/CD:** All quality gates must pass
{% endif -%}
- **Timeline:** Most PRs reviewed within 24-48 hours

{% if include_github_actions -%}

### CI/CD Expectations

**When enabled** (`include_github_actions: true`), this project includes automated quality gates that agents should be aware of.

**GitHub Actions workflows:**

{% if include_github_actions -%}
1. **test.yml** - Full test suite on every push/PR
   - Runs: `pytest` with coverage
   - Required: ‚â•{{ test_coverage_threshold if include_tests else '85' }}% coverage
   - Triggers: Push to all branches, pull requests

2. **lint.yml** - Code quality checks
   - Runs: `ruff check`, `ruff format --check`, `mypy`
   - Required: No linting errors, formatted code, type-safe
   - Triggers: Push to all branches, pull requests

3. **smoke.yml** - Quick smoke tests
   - Runs: Fast validation tests (<30s)
   - Required: Basic functionality works
   - Triggers: Every push (fast feedback)

{% if include_docker -%}
4. **docker.yml** - Container builds (if Docker enabled)
   - Runs: `docker build`, `docker-compose up`, health checks
   - Required: Image builds successfully, services start healthy
   - Triggers: Push to main, pull requests touching Docker files
{% endif -%}

5. **release.yml** - Automated releases
   - Runs: Version bump, changelog, PyPI publish
   - Required: Tests pass, version valid, PyPI credentials configured
   - Triggers: Manual workflow dispatch, tags

6. **codeql.yml** - Security scanning
   - Runs: CodeQL analysis for vulnerabilities
   - Required: No critical security issues
   - Triggers: Weekly schedule, pull requests

7. **dependency-review.yml** - Dependency vulnerabilities
   - Runs: Dependency vulnerability scanning
   - Required: No high/critical vulnerabilities in new dependencies
   - Triggers: Pull requests
{% endif -%}

**What CI will check before merge:**

```bash
{% if include_justfile -%}
# Locally verify CI will pass
just pre-merge

{% endif -%}# This runs the same checks as CI:
{% if include_pre_commit -%}
# 1. Linting: ruff check ‚Üí No errors
# 2. Formatting: ruff format --check ‚Üí Code formatted
# 3. Type checking: mypy ‚Üí Type-safe
{% endif -%}
{% if include_tests -%}
# 4. Tests: pytest ‚Üí All tests pass
# 5. Coverage: pytest --cov ‚Üí ‚â•{{ test_coverage_threshold if include_tests else '85' }}%
{% endif -%}
{% if include_docker -%}
# 6. Docker: docker build ‚Üí Image builds successfully
{% endif -%}
```

**For agents:** Run {% if include_justfile %}`just pre-merge`{% else %}`pytest` and linting checks{% endif %} before creating PRs to avoid CI failures.

**CI failure recovery:**
1. Check workflow logs in GitHub Actions tab
2. Run failing command locally to reproduce
3. Fix issue and push new commit (CI will re-run)
4. If tests pass locally but fail in CI, check for environment differences

{% endif -%}

---

## Architecture Overview

[Describe your project's architecture here. Include diagrams, key design patterns, and architectural decisions.]

### Key Design Patterns

- **[Pattern 1]:** [Description]
- **[Pattern 2]:** [Description]
- **[Pattern 3]:** [Description]

### Configuration Management

[Describe how configuration works in your project, including environment variables, config files, etc.]

---

## Key Constraints & Design Decisions

### Target Audience

{{ project_description }}

{% if project_type == 'mcp_server' -%}
**CRITICAL:** {{ project_name }} is designed for **LLM-intelligent MCP clients** (Claude Desktop, Cursor, Roo Code).

- ‚úÖ **FOR LLM agents** - Claude Desktop, Cursor, custom MCP clients
- ‚úÖ **FOR programmatic use** - Python API, automation workflows
- ‚ùå **NOT for human CLI users** - No interactive wizards or watch modes

**Implication:** All features prioritize agent ergonomics over human UX.

{% endif -%}
### [Additional Constraints]

[Document your project-specific constraints and design decisions here.]

{% if include_vision_docs -%}

---

## Strategic Design

### Balancing Current Priorities with Future Vision

**The Balance:**
- ‚úÖ **Deliver:** Ship current commitments on time
- ‚úÖ **Design for evolution:** Keep future doors open (extension points)
- ‚úÖ **Refactor strategically:** When it serves both present and future
- ‚ùå **NOT:** Premature optimization, gold plating, scope creep

**Key Insight:** Build for today, design for tomorrow. Don't implement Wave 2 features in Wave 1, but don't paint yourself into corners either.

### Vision-Aware Implementation Pattern

**When implementing features, ask:**

1. **Architecture Check:** "Does this design block future capabilities in [dev-docs/vision/](dev-docs/vision/)?"
   - ‚úÖ YES ‚Üí Refactor before implementing
   - ‚úÖ NO ‚Üí Proceed

2. **Refactoring Signal:** "Should I refactor this now?"
   ```
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Does it help current work (Wave 1)?                 ‚îÇ
   ‚îÇ   NO ‚Üí DEFER (focus on current deliverables)       ‚îÇ
   ‚îÇ   YES ‚Üí Continue ‚Üì                                  ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ Does it unblock future capabilities?                ‚îÇ
   ‚îÇ   YES ‚Üí LIKELY REFACTOR (strategic investment)     ‚îÇ
   ‚îÇ   NO ‚Üí Continue ‚Üì                                   ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ Cost vs. benefit?                                    ‚îÇ
   ‚îÇ   HIGH COST ‚Üí DEFER (wait for Wave 2 commitment)   ‚îÇ
   ‚îÇ   LOW COST ‚Üí REFACTOR (small prep, big payoff)     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ```

3. **Decision Documentation:** Where to record decisions
{% if include_memory_system -%}
   - **Knowledge notes:** `{{ package_name }}-memory knowledge create "Decision: [topic]"`
   - **Tags:** Use `architecture`, `vision`, `wave-N` tags for discoverability
{% else -%}
   - **Architecture Decision Records (ADRs):** `dev-docs/architecture/ADR-00X-name.md`
   - **Code comments:** Explain why (not what) in critical sections
{% endif -%}

### Practical Examples

{% if project_type == 'mcp_server' -%}
**Example: Building Tool Interface**

**Scenario:** Wave 1 needs simple tool responses. Wave 2 vision includes tool chaining.

**‚ùå DON'T (Premature Optimization):**
```python
# DON'T build tool chaining now
async def get_data(query: str) -> str:
    # Implements full chaining system (Wave 2 feature)
    return chain_tools([tool_a, tool_b])(query)  # Not needed yet!
```

**‚úÖ DO (Extension Point):**
```python
# DO return structured data (enables future chaining)
async def get_data(query: str) -> dict:
    """Returns structured response (extensible for Wave 2)."""
    return {
        "result": process_query(query),
        "metadata": {"timestamp": now(), "version": "1.0"}
    }
    # Wave 2 can add: "next_tool": "tool_b", "chain_id": "..."
```

{% elif project_type == 'library' -%}
**Example: API Design**

**Scenario:** Wave 1 needs basic processing. Wave 2 vision includes plugin system.

**‚ùå DON'T (Gold Plating):**
```python
# DON'T build plugin system now
class Processor:
    def __init__(self):
        self.plugin_manager = PluginManager()  # Not needed yet!
        self.plugins = self.plugin_manager.discover()

    def process(self, data: str) -> str:
        # Complex plugin orchestration
        return self.plugin_manager.execute_all(data)
```

**‚úÖ DO (Protocol/Interface):**
```python
# DO use protocols (extensible for Wave 2 plugins)
from typing import Protocol

class ProcessorStrategy(Protocol):
    """Strategy interface (enables future plugins)."""
    def process(self, data: str) -> str: ...

class Processor:
    def __init__(self, strategy: ProcessorStrategy | None = None):
        self.strategy = strategy or DefaultStrategy()

    def process(self, data: str) -> str:
        return self.strategy.process(data)
        # Wave 2 can add: plugin discovery, registration
```

{% elif project_type == 'cli_tool' -%}
**Example: Command Structure**

**Scenario:** Wave 1 needs basic commands. Wave 2 vision includes plugin commands.

**‚ùå DON'T (Scope Creep):**
```python
# DON'T build plugin loading now
@click.group()
def cli():
    load_plugins()  # Not needed yet!
    discover_external_commands()  # Not needed yet!
```

**‚úÖ DO (Modular Structure):**
```python
# DO organize commands modularly (enables future plugins)
@click.group()
def cli():
    """Main CLI (extensible for Wave 2 plugins)."""
    pass

# Each command is a module
cli.add_command(cmd_process)
cli.add_command(cmd_analyze)
# Wave 2 can add: plugin discovery, external command loading
```

{% elif project_type == 'web_service' -%}
**Example: API Endpoint Design**

**Scenario:** Wave 1 needs basic CRUD. Wave 2 vision includes webhooks.

**‚ùå DON'T (Future Feature Now):**
```python
# DON'T implement webhooks now
@app.post("/items")
async def create_item(item: Item):
    result = db.create(item)
    await webhook_manager.notify_all(result)  # Not needed yet!
    return result
```

**‚úÖ DO (Event Hook):**
```python
# DO emit events (enables future webhooks)
@app.post("/items")
async def create_item(item: Item):
    result = db.create(item)
    await event_bus.emit("item.created", result)  # Hook for Wave 2
    return result
    # Wave 2 can add: webhook subscriptions to event_bus
```
{% endif -%}

### Refactoring Decision Framework

**Use this checklist before refactoring:**

- [ ] **Current Work:** Does this help Wave 1 deliverables?
- [ ] **Future Vision:** Check [dev-docs/vision/](dev-docs/vision/) - does this prepare for next wave?
- [ ] **Cost Assessment:** Low cost (<2 hours) or high cost (>1 day)?
- [ ] **Decision:** Apply framework above ‚Üí Refactor now or defer?
- [ ] **Documentation:** Record decision ({% if include_memory_system %}knowledge note{% else %}ADR{% endif %})

### Capturing Knowledge for Future Agents

{% if include_memory_system -%}
**Use A-MEM (Agentic Memory) patterns:**

1. **Emit Events:** Track architectural decisions
   ```python
   from {{ package_name }}.memory import emit_event

   emit_event(
       event_type="architecture.decision",
       data={
           "decision": "Use dict returns for tool extensibility",
           "rationale": "Enables Wave 2 tool chaining",
           "wave": "wave-2-preparation"
       },
       status="success"
   )
   ```

2. **Create Knowledge Notes:**
   ```bash
   echo "Decision: Tool Response Format

   Context: Wave 1 tools return simple data, Wave 2 vision includes tool chaining.

   Decision: Return dict (not str) from all tools.

   Rationale:
   - Low cost refactor (1 hour)
   - Unblocks Wave 2 tool chaining
   - Backward compatible (wrap str in dict)

   Tags: architecture, vision, wave-2, tools
   " | {{ package_name }}-memory knowledge create "Tool Response Format"
   ```

3. **Link to Vision:**
   - Reference vision waves in knowledge notes
   - Tag notes with `wave-N` for future discoverability
   - Query past decisions: `{{ package_name }}-memory knowledge search --tag wave-2`

{% else -%}
**Use Architecture Decision Records (ADRs):**

1. **Create ADR:**
   ```bash
   touch dev-docs/architecture/ADR-001-tool-response-format.md
   ```

2. **Link to Vision:**
   - Reference [dev-docs/vision/CAPABILITY_EVOLUTION.md](dev-docs/vision/CAPABILITY_EVOLUTION.md) in ADR
   - Explain which wave this prepares for
   - Document decision criteria applied

3. **Update Vision Doc:**
   - If decision affects wave feasibility, update vision document
   - Record in quarterly review section
{% endif -%}

### Quick Reference: Strategic Design Checklist

**Before implementing any feature:**

1. ‚úÖ **Check ROADMAP.md:** Is this in current committed work?
2. ‚úÖ **Check vision:** Does this align with evolutionary direction?
3. ‚úÖ **Apply framework:** Refactor now or defer? (use flowchart above)
4. ‚úÖ **Document:** Record decision for future agents
5. ‚úÖ **Code:** Implement with extension points, not future features

**Remember:** Deliver today, design for tomorrow. No gold plating!

{% endif -%}

---

## Common Tasks for Agents

{#
  PATTERN FOR FEATURE SECTIONS
  ============================

  When adding new optional features to chora-base, follow this pattern for
  ergonomic agent discoverability:

  {% if include_feature_name -%}
  ### Feature Name

  **When enabled** (`include_feature_name: true`), brief description.

  **Discovery:**
  ```bash
  {% if include_justfile -%}
  # List feature commands
  just --list | grep feature

  {% endif -%}# Available commands:
  # - command-name           Description
  # - another-command        Description
  ```

  **Common workflows:**

  ```bash
  {% if include_justfile -%}
  # Workflow 1
  just command-name

  # Workflow 2
  just another-command
  {% else -%}
  # Direct commands (no justfile)
  direct-command args
  {% endif -%}
  ```

  **For detailed workflows:** See [FEATURE_GUIDE.md](FEATURE_GUIDE.md)

  **Adopter responsibilities (wiring required):**
  - [ ] Configuration item 1
  - [ ] Configuration item 2
  - [ ] Testing requirement

  **Expected results:**
  - Metric 1: value
  - Metric 2: value

  {% endif -%}

  KEY PRINCIPLES:
  1. Conditional on feature flag ({% if include_feature %})
  2. Discovery via `just --list | grep` (ergonomic for agents)
  3. Link to detailed docs (don't duplicate content)
  4. Clarify adopter wiring responsibilities
  5. Include expected metrics/results

  This keeps AGENTS.md as capability catalog while detailed guides remain
  as reference manuals.
#}

{% if include_justfile -%}
### Task Discovery (START HERE)

**First step when working in this project: Discover available tasks**

```bash
just --list
```

This provides a machine-readable catalog of all development tasks.

**Why `just` for agents:**
- **Self-documenting**: `just --list` reveals all tasks instantly (no prose parsing)
- **Consistent**: Same commands across all chora-base projects
- **Structured**: Machine-parseable task catalog
- **Composable**: `just --show <task>` reveals implementation details
- **Transferable**: Commands learned here work in all chora-base projects

**Pattern**: Always start with `just --list` when working in a new chora-base project. Store commands as ecosystem-wide patterns, not project-specific.

**Example workflow:**
```bash
# Discover tasks
just --list
# Output: test, lint, pre-merge, build, etc.

# Understand a specific task
just --show pre-merge
# Output: shows it runs ./scripts/pre-merge.sh

# Execute
just pre-merge
```

**Memory note**: Store as:
```json
{
  "ecosystem": "chora-base",
  "discovery_command": "just --list",
  "common_tasks": {
    "test": "just test",
    "pre_merge": "just pre-merge",
    "build": "just build"
  },
  "applies_to": "all_chora_base_projects"
}
```

This knowledge transfers to mcp-n8n, chora-compose, and all future chora-base projects.

{% endif -%}
{% if project_type == 'mcp_server' -%}
### Adding a New MCP Tool

**Before you start**: Read [NAMESPACES.md](NAMESPACES.md) for naming conventions and namespace registry.

1. Create tool function in `src/{{ package_name }}/tools/your_tool.py`
2. Register tool with `@mcp.tool()` decorator{% if mcp_enable_namespacing %}
3. Use `make_tool_name("your_tool")` for consistent namespacing
4. {% else %}
3. Choose a descriptive snake_case name
4. {% endif %}{% if include_memory_system %}Add memory integration (emit events)
5. {% endif %}Add unit test in `tests/unit/test_your_tool.py`
6. {% if include_memory_system %}Add integration test with memory validation
7. {% endif %}Update README.md tool list
8. **Update [NAMESPACES.md](NAMESPACES.md) registry** - Add your tool to the table
9. Run tests: `{% if include_justfile %}just test{% else %}pytest{% endif %}`

**Example:**
```python
{% if include_memory_system -%}
from {{ package_name }}.memory import emit_event, TraceContext
{% endif -%}
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("{{ project_name }}")

@mcp.tool()
async def your_tool(param: str) -> dict:
    """Your tool description.

    Args:
        param: Parameter description

    Returns:
        Result dictionary
    """
{% if include_memory_system -%}
    # Emit start event
    emit_event("tool.your_tool.started", status="pending", metadata={"param": param})

{% endif -%}
    try:
        # Your tool logic here
        result = process(param)
{% if include_memory_system -%}
        # Emit success event
        emit_event("tool.your_tool.completed", status="success", metadata={"result_count": len(result)})
{% endif -%}
        return {"success": True, "data": result}
    except Exception as e:
{% if include_memory_system -%}
        # Emit failure event
        emit_event("tool.your_tool.failed", status="failure", metadata={"error": str(e)})
{% endif -%}
        return {"success": False, "error": str(e)}
```

{% endif -%}
{% if include_documentation_standard -%}
### Documentation System

**When enabled** (`include_documentation_standard: true`), this project includes machine-readable documentation with health metrics and programmatic querying.

**Discovery:**
```bash
{% if include_justfile -%}
# Documentation commands
just --list | grep docs

{% endif -%}# Available commands (via scripts):
# - python scripts/docs_metrics.py    Generate health metrics
# - python scripts/query_docs.py      Query docs programmatically
# - python scripts/extract_tests.py   Extract test scenarios
```

**Common workflows:**

```bash
# Check documentation health
python scripts/docs_metrics.py

# Query documentation (JSON API for AI agents)
python scripts/query_docs.py function get_example

# Extract test scenarios from docstrings
python scripts/extract_tests.py

# View metrics report
cat DOCUMENTATION_METRICS.md
```

**Documentation health scoring:**
- **90-100:** Excellent (comprehensive, up-to-date)
- **70-89:** Good (minor gaps)
- **50-69:** Needs improvement (significant gaps)
- **0-49:** Critical (major documentation debt)

**For agents:** Use `query_docs.py` to programmatically discover functions, parameters, return types, and examples without parsing source code.

**Adopter responsibilities (wiring required):**
- [ ] Write comprehensive docstrings following NumPy/Google style
- [ ] Include `# TEST:` markers in docstrings for extractable scenarios
- [ ] Review DOCUMENTATION_METRICS.md quarterly and address gaps
- [ ] Add examples to critical functions (user-facing API)

**See:** [DOCUMENTATION_STANDARD.md](DOCUMENTATION_STANDARD.md) for complete documentation guidelines.

{% endif -%}
### Debugging Common Issues

```bash
# Check logs
{% if include_justfile -%}
just logs  # If justfile has log task
# OR
{% endif -%}
tail -f logs/{{ package_name }}.log

# Test single component
python -m {{ package_name }}.module_name

# Check environment
env | grep {{ package_name | upper }}

# Validate configuration
python -c "from {{ package_name }} import config; print(config)"
```

{% if include_vision_docs -%}
### Design Decision: Check Against Vision

**When:** Before making architectural decisions or significant refactors

**Steps:**

1. **Check current priority:**
   ```bash
   cat ROADMAP.md | head -50
   # Current: [Your current sprint/milestone]
   ```

2. **Check long-term vision:**
   ```bash
   cat dev-docs/vision/CAPABILITY_EVOLUTION.md | head -100
   # Future waves: [Your capability themes]
   ```

3. **Apply decision framework:**
   - **Does this help current work?** (YES ‚Üí continue)
   - **Does this align with vision?** (YES ‚Üí good sign)
   - **Cost vs. benefit?** (LOW COST ‚Üí likely proceed)

4. **Document decision:**
{% if include_memory_system -%}
   ```bash
   # Create knowledge note
   echo "Decision: [Your decision]

   Context: [Current situation]

   Decision: [What you decided]

   Rationale:
   - Helps Wave 1 deliverables: [How]
   - Aligns with Wave 2 vision: [Which capability]
   - Low cost: [Effort estimate]

   Outcome: [Expected result]

   Tags: architecture, vision, wave-N, decision
   " | {{ package_name }}-memory knowledge create "Decision: [Topic]"
   ```
{% else -%}
   ```bash
   # Create architecture decision record
   touch dev-docs/architecture/ADR-00X-decision-name.md
   ```

   **ADR Template:**
   ```markdown
   # ADR-00X: [Decision Title]

   **Status:** Accepted
   **Date:** YYYY-MM-DD
   **Wave:** Wave N preparation

   ## Context
   [Current situation requiring decision]

   ## Decision
   [What we decided to do]

   ## Rationale
   - Helps current work: [How]
   - Aligns with vision: [Which wave/capability]
   - Cost vs. benefit: [Analysis]

   ## Consequences
   - Positive: [Benefits]
   - Negative: [Trade-offs]
   - Neutral: [Other impacts]

   ## Related
   - [Link to vision doc wave]
   - [Link to related ADRs]
   ```
{% endif -%}

5. **Link to vision:**
   - If prepares for future waves, note it in documentation
{% if include_memory_system -%}
   - Add tags to knowledge notes for discoverability: `wave-2`, `architecture`, `vision`
{% endif -%}
   - Update vision document if decision affects feasibility

**Example Decision:**

**Scenario:** Should we refactor tool responses from `str` to `dict`?

1. **Current work:** Wave 1 needs simple responses ‚Üí `str` works
2. **Vision:** Wave 2 includes tool chaining ‚Üí needs structured data (`dict`)
3. **Cost:** Low (1-2 hours to refactor)
4. **Decision:** ‚úÖ REFACTOR NOW (serves both present and future)

{% endif -%}

---

## Project Structure

```
{{ project_slug }}/
‚îú‚îÄ‚îÄ src/{{ package_name }}/       # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
{% if project_type == 'mcp_server' -%}
‚îÇ   ‚îú‚îÄ‚îÄ server.py               # MCP server entry point
{% elif project_type == 'cli_tool' or include_cli -%}
‚îÇ   ‚îú‚îÄ‚îÄ cli/                    # CLI interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
{% endif -%}
{% if include_memory_system -%}
‚îÇ   ‚îú‚îÄ‚îÄ memory/                 # Agent memory system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event_log.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge_graph.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trace.py
{% endif -%}
‚îÇ   ‚îî‚îÄ‚îÄ [your modules]
{% if include_tests -%}
‚îú‚îÄ‚îÄ tests/                      # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ smoke/                  # Smoke tests (<30s)
‚îÇ   ‚îú‚îÄ‚îÄ integration/            # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py               # Unit tests
{% endif -%}
‚îú‚îÄ‚îÄ scripts/                    # Automation scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                # One-command setup
‚îÇ   ‚îú‚îÄ‚îÄ venv-create.sh          # Create virtual environment
‚îÇ   ‚îî‚îÄ‚îÄ [other scripts]
{% if include_development_docs or include_troubleshooting -%}
‚îú‚îÄ‚îÄ docs/                       # Documentation
{% if include_development_docs -%}
‚îÇ   ‚îú‚îÄ‚îÄ DEVELOPMENT.md          # Developer deep dive
{% endif -%}
{% if include_troubleshooting -%}
‚îÇ   ‚îî‚îÄ‚îÄ TROUBLESHOOTING.md      # Problem-solution guide
{% endif -%}
{% endif -%}
{% if include_github_actions -%}
‚îú‚îÄ‚îÄ .github/workflows/          # CI/CD pipelines
‚îÇ   ‚îú‚îÄ‚îÄ test.yml                # Test workflow
‚îÇ   ‚îî‚îÄ‚îÄ lint.yml                # Lint workflow
{% endif -%}
{% if include_memory_system -%}
‚îú‚îÄ‚îÄ .chora/memory/              # Agent memory (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # Memory architecture docs
‚îÇ   ‚îú‚îÄ‚îÄ events/                 # Event log (JSONL format)
‚îÇ   ‚îú‚îÄ‚îÄ knowledge/              # Knowledge notes (YAML frontmatter)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ notes/*.md          # Individual notes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ links.json          # Bidirectional links
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tags.json           # Tag index
‚îÇ   ‚îî‚îÄ‚îÄ profiles/               # Agent-specific profiles
{% endif -%}
‚îú‚îÄ‚îÄ pyproject.toml              # Python packaging & tool config
{% if include_justfile -%}
‚îú‚îÄ‚îÄ justfile                    # Task runner commands
{% endif -%}
‚îú‚îÄ‚îÄ .env.example                # Example environment variables
‚îú‚îÄ‚îÄ .gitignore                  # Git ignore patterns
‚îú‚îÄ‚îÄ README.md                   # Human-readable project overview
‚îú‚îÄ‚îÄ AGENTS.md                   # This file (machine-readable instructions)
{% if include_contributing -%}
‚îú‚îÄ‚îÄ CONTRIBUTING.md             # Contribution guidelines
{% endif -%}
‚îî‚îÄ‚îÄ LICENSE                     # {{ license }} license
```

{% if include_memory_system -%}
### Knowledge Note Metadata Standards

Knowledge notes (`.chora/memory/knowledge/notes/*.md`) use **YAML frontmatter** following Zettelkasten best practices for machine-readable metadata.

**Required Frontmatter Fields:**
- `id`: Unique note identifier (kebab-case)
- `created`: ISO 8601 timestamp
- `updated`: ISO 8601 timestamp
- `tags`: Array of topic tags for search/organization

**Optional Frontmatter Fields:**
- `confidence`: `low` | `medium` | `high` - Solution reliability
- `source`: `agent-learning` | `human-curated` | `external` | `research`
- `linked_to`: Array of related note IDs (bidirectional linking)
- `status`: `draft` | `validated` | `deprecated`
- `author`: Agent or human creator
- `related_traces`: Array of trace IDs that led to this knowledge

**Example Knowledge Note:**

```markdown
---
id: api-timeout-solution
created: 2025-01-17T10:00:00Z
updated: 2025-01-17T12:30:00Z
tags: [troubleshooting, api, performance]
confidence: high
source: agent-learning
linked_to: [connection-pool-tuning, retry-patterns]
status: validated
author: claude-code
related_traces: [abc123, def456]
---

# API Timeout Solution

## Problem
API calls timing out after 30s during high load...

## Solution
Increase timeout to 60s and implement retry with exponential backoff...

## Evidence
- Trace abc123: Successful completion at 45s
- Trace def456: Successful completion at 52s
- Load test: 98% success rate with new settings
```

**Why YAML Frontmatter?**
- ‚úÖ **Semantic Search**: Query by confidence, tags, or date (`grep "confidence: high"`)
- ‚úÖ **Tool Compatibility**: Works with Obsidian, Zettlr, LogSeq, Foam
- ‚úÖ **Knowledge Graph**: Enables bidirectional linking and visualization
- ‚úÖ **Agent Decision-Making**: Filter by confidence level for solution reliability

**Reference:** See [.chora/memory/README.md](.chora/memory/README.md) for complete schema documentation.

{% endif -%}
---

## Documentation Philosophy

### Di√°taxis Framework

{{ project_name }} documentation follows the [Di√°taxis framework](https://diataxis.fr/), serving **two first-class audiences**:

1. **Human Developers** - Learning, understanding, decision-making
2. **AI Agents** - Task execution, reference lookup, machine-readable instructions

**Four Quadrants:**

| Type | Purpose | Primary Audience | When to Use |
|------|---------|------------------|-------------|
| **Tutorials** | Learning-oriented | Humans (new users) | "I want to learn how {{ project_name }} works" |
| **How-To Guides** | Task-oriented | Humans + Agents | "I want to accomplish a specific task" |
| **Reference** | Information-oriented | Humans + Agents | "I need to look up a fact/command/API" |
| **Explanation** | Understanding-oriented | Humans | "I want to understand why/how this works" |

### For AI Agents (Recommended Reading Order)

**When starting work on {{ project_name }}:**

1. **Start here:** AGENTS.md (this file) - Machine-readable project instructions
2. **Quick reference:** How-To Guides - Executable task recipes
   - How to add new features
   - How to run tests
   - How to deploy
3. **Lookup facts:** Reference Docs - API specs, configuration options, commands
4. **Skip:** Tutorials (for human learning) and Explanations (conceptual background)

**Example: Agent workflow for "Add new feature X"**

```bash
# 1. Read AGENTS.md section: "Common Tasks for Agents" ‚Üí "Adding a New MCP Tool"
# 2. Follow steps 1-7 (create file, register tool, add tests, etc.)
# 3. If unclear on testing: Consult "Testing Instructions" section in AGENTS.md
# 4. If need API reference: Read relevant module docstrings or Reference docs
# 5. Run pre-merge: `just pre-merge` (from AGENTS.md "Pre-Merge Verification")
```

### For Human Developers (Recommended Learning Path)

**New to {{ project_name }}:**

1. **README.md** - Project overview, quick start (5 minutes)
2. **Tutorial** - Guided learning experience (30-60 minutes)
{% if include_development_docs -%}
3. **DEVELOPMENT.md** - Developer deep dive (architecture, debugging)
{% endif -%}
4. **How-To Guides** - Task-specific recipes (as needed)
5. **Reference Docs** - Lookup API details (as needed)
6. **Explanation Docs** - Understand design decisions (optional)

### Documentation Hierarchy

```
docs/
‚îú‚îÄ‚îÄ README.md                   # Human entry point (project overview)
‚îú‚îÄ‚îÄ AGENTS.md                   # Agent entry point (this file)
{% if include_contributing -%}
‚îú‚îÄ‚îÄ CONTRIBUTING.md             # Human contributor guide
{% endif -%}
{% if include_development_docs -%}
‚îú‚îÄ‚îÄ DEVELOPMENT.md              # Developer deep dive
{% endif -%}
{% if include_troubleshooting -%}
‚îú‚îÄ‚îÄ TROUBLESHOOTING.md          # Problem-solution guide
{% endif -%}
‚îî‚îÄ‚îÄ [additional docs]/
```

**Quick Reference:**

- **For agents:** AGENTS.md ‚Üí How-To Guides ‚Üí Reference Docs
- **For humans:** README ‚Üí Tutorials ‚Üí How-To Guides ‚Üí Explanations

### DDD/BDD/TDD Workflow

This project follows the Chora ecosystem's integrated DDD/BDD/TDD workflow:

1. **DDD Phase** - Write API reference docs FIRST (documentation-driven design)
2. **BDD Phase** - Write scenarios SECOND (behavior-driven development)
3. **TDD Phase** - Red-Green-Refactor THIRD (test-driven development)
4. **CI Phase** - Automated quality gates
5. **Merge & Release** - Semantic versioning

**Why this order matters:**

- **Docs first** ensures clear API design before implementation
- **Scenarios second** captures expected behavior as executable specs
- **Tests third** drives implementation with fast feedback loop
- **CI validates** all quality gates pass before merge
- **Semantic versioning** communicates changes to users

**For agents:** Follow this workflow when adding new features. Write docs ‚Üí scenarios ‚Üí tests ‚Üí implementation.

---

## Troubleshooting

### Application Won't Start

```bash
# Check Python version
python --version  # Must be {{ python_version }}+

# Check virtual environment
which python  # Should be .venv/bin/python

# Reinstall dependencies
./scripts/venv-create.sh

# Check environment variables
cat .env

# Test application directly
python -m {{ package_name }}{% if project_type == 'mcp_server' %}.server{% elif project_type == 'cli_tool' or include_cli %}.cli.main{% endif %}
```

---

## Related Resources

- **Repository:** https://github.com/{{ github_username }}/{{ project_slug }}
- **Chora Base Template:** https://github.com/liminalcommons/chora-base
- **Chora Composer:** https://github.com/liminalcommons/chora-composer
- **Chora Platform:** https://github.com/liminalcommons/chora-platform
{% if project_type == 'mcp_server' -%}
- **MCP Specification:** https://modelcontextprotocol.io/
{% endif -%}

---

**Version:** {{ project_version }}
**Last Updated:** [Update date]
**Format:** AGENTS.md standard (OpenAI/Google/Sourcegraph)
ü§ñ Generated with [chora-base](https://github.com/liminalcommons/chora-base) template
