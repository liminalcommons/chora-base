# How to List and Retrieve Content from Storage

**Goal**: Learn how to list content in ephemeral storage, filter and search, retrieve by ID, and use batch retrieval operations.

**Time**: 10-15 minutes

**Prerequisites**:
- Chora Compose installed
- Basic understanding of [ephemeral storage](manage-ephemeral-storage.md)

---

## Overview

Ephemeral storage stores generated content with versioning. This guide shows you how to:

- **List all content** in storage
- **Filter and search** by criteria
- **Retrieve specific content** by ID
- **Batch retrieve** multiple items
- **Inspect metadata** for stored content

---

## Quick Reference

### Common Operations

| Task | Command | Example |
|------|---------|---------|
| List all content IDs | `list_content()` | `["api-docs", "readme", "release-notes"]` |
| Retrieve latest version | `retrieve(id)` | `retrieve("api-docs")` |
| Retrieve specific version | `retrieve(id, strategy)` | `retrieve("api-docs", strategy="timestamp:2025-10-21")` |
| Get version count | `len(list_versions(id))` | `5 versions` |
| Check if exists | `content_id in list_content()` | `True` or `False` |

---

## Listing All Content

### Basic Listing

```python
from chora_compose.storage.ephemeral import EphemeralStorageManager

storage = EphemeralStorageManager()

# List all content IDs
content_ids = storage.list_content()
print(f"Found {len(content_ids)} content items")
for content_id in content_ids:
    print(f"  - {content_id}")
```

**Output**:
```
Found 3 content items
  - api-docs
  - readme
  - release-notes
```

### Implementation

```python
def list_content(self) -> list[str]:
    """List all content IDs in storage."""
    return [
        d.name for d in self.base_path.iterdir()
        if d.is_dir() and not d.name.startswith(".")
    ]
```

---

## Filtering and Searching

### Filter by Date

```python
from datetime import datetime, timedelta, timezone

def list_recent_content(storage, days=7):
    """List content modified in last N days."""
    cutoff = datetime.now(timezone.utc) - timedelta(days=days)
    recent = []

    for content_id in storage.list_content():
        versions = storage.list_versions(content_id)
        if versions and versions[-1].timestamp_dt >= cutoff:
            recent.append(content_id)

    return recent

# Usage
recent = list_recent_content(storage, days=7)
print(f"Content modified in last 7 days: {recent}")
```

### Filter by Format

```python
def list_by_format(storage, format="md"):
    """List content with specific format."""
    results = []

    for content_id in storage.list_content():
        versions = storage.list_versions(content_id)
        if versions and versions[-1].format == format:
            results.append(content_id)

    return results

# Usage
markdown_docs = list_by_format(storage, format="md")
print(f"Markdown documents: {markdown_docs}")
```

### Search by Metadata

```python
def search_by_generator(storage, generator_type):
    """Find content generated by specific generator."""
    results = []

    for content_id in storage.list_content():
        versions = storage.list_versions(content_id)
        latest = versions[-1] if versions else None
        if latest and latest.metadata.get("generator") == generator_type:
            results.append(content_id)

    return results

# Usage
jinja2_docs = search_by_generator(storage, "jinja2")
print(f"Jinja2-generated docs: {jinja2_docs}")
```

---

## Retrieving Content

### Retrieve Latest Version

```python
# Simple retrieval (latest version)
content = storage.retrieve("api-docs")
print(content)
```

### Retrieve with Error Handling

```python
def safe_retrieve(storage, content_id):
    """Retrieve with error handling."""
    try:
        return storage.retrieve(content_id)
    except FileNotFoundError:
        print(f"❌ Content not found: {content_id}")
        return None

# Usage
content = safe_retrieve(storage, "api-docs")
if content:
    print(f"✅ Retrieved {len(content)} bytes")
```

### Retrieve All Versions

```python
# Get all versions as list
all_versions = storage.retrieve("api-docs", strategy="all")

print(f"Found {len(all_versions)} versions")
for i, content in enumerate(all_versions, 1):
    print(f"Version {i}: {len(content)} bytes")
```

### Retrieve Specific Version

```python
# By timestamp
content = storage.retrieve("api-docs", strategy="timestamp:2025-10-21T10:30")

# By semantic version (if metadata has version)
content = storage.retrieve("api-docs", strategy="version:1.0.0")
```

---

## Batch Retrieval

### Retrieve Multiple Items

```python
def batch_retrieve(storage, content_ids):
    """Retrieve multiple content items."""
    results = {}

    for content_id in content_ids:
        try:
            results[content_id] = storage.retrieve(content_id)
        except FileNotFoundError:
            results[content_id] = None

    return results

# Usage
ids = ["api-docs", "readme", "release-notes"]
contents = batch_retrieve(storage, ids)

for content_id, content in contents.items():
    if content:
        print(f"✅ {content_id}: {len(content)} bytes")
    else:
        print(f"❌ {content_id}: Not found")
```

### Parallel Batch Retrieval

```python
from concurrent.futures import ThreadPoolExecutor

def parallel_batch_retrieve(storage, content_ids, max_workers=5):
    """Retrieve multiple items in parallel."""
    def retrieve_one(content_id):
        try:
            return (content_id, storage.retrieve(content_id))
        except FileNotFoundError:
            return (content_id, None)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = dict(executor.map(lambda id: retrieve_one(id), content_ids))

    return results

# Usage
ids = ["api-docs", "readme", "release-notes"]
contents = parallel_batch_retrieve(storage, ids)
```

---

## Inspecting Metadata

### Get Version Metadata

```python
# List versions with metadata
versions = storage.list_versions("api-docs")

for version in versions:
    print(f"Timestamp: {version.timestamp}")
    print(f"Format: {version.format}")
    print(f"Size: {version.metadata.get('size')} bytes")
    print(f"Generator: {version.metadata.get('generator', 'unknown')}")
    print()
```

### Build Content Catalog

```python
def build_catalog(storage):
    """Build catalog of all content with metadata."""
    catalog = {}

    for content_id in storage.list_content():
        versions = storage.list_versions(content_id)
        if not versions:
            continue

        latest = versions[-1]
        catalog[content_id] = {
            "version_count": len(versions),
            "latest_timestamp": latest.timestamp,
            "format": latest.format,
            "size": latest.metadata.get("size"),
            "generator": latest.metadata.get("generator"),
        }

    return catalog

# Usage
catalog = build_catalog(storage)
for content_id, info in catalog.items():
    print(f"{content_id}:")
    print(f"  Versions: {info['version_count']}")
    print(f"  Latest: {info['latest_timestamp']}")
    print(f"  Format: {info['format']}")
    print(f"  Generator: {info['generator']}")
```

---

## Pagination

### Simple Pagination

```python
def paginate(items, page=1, per_page=10):
    """Paginate a list of items."""
    start = (page - 1) * per_page
    end = start + per_page
    return items[start:end]

# Usage
all_content = storage.list_content()
page1 = paginate(all_content, page=1, per_page=10)
page2 = paginate(all_content, page=2, per_page=10)
```

### Pagination with Metadata

```python
class PaginatedResult:
    def __init__(self, items, page, per_page, total):
        self.items = items
        self.page = page
        self.per_page = per_page
        self.total = total
        self.pages = (total + per_page - 1) // per_page

def paginate_with_metadata(items, page=1, per_page=10):
    """Paginate with metadata."""
    total = len(items)
    start = (page - 1) * per_page
    end = start + per_page

    return PaginatedResult(
        items=items[start:end],
        page=page,
        per_page=per_page,
        total=total
    )

# Usage
result = paginate_with_metadata(storage.list_content(), page=1, per_page=10)
print(f"Page {result.page} of {result.pages}")
print(f"Showing {len(result.items)} of {result.total} items")
```

---

## Advanced Patterns

### Content Summary

```python
def summarize_storage(storage):
    """Generate storage summary."""
    content_ids = storage.list_content()
    total_versions = 0
    total_size = 0
    formats = {}

    for content_id in content_ids:
        versions = storage.list_versions(content_id)
        total_versions += len(versions)

        for version in versions:
            size = version.metadata.get("size", 0)
            total_size += size
            fmt = version.format
            formats[fmt] = formats.get(fmt, 0) + 1

    return {
        "content_count": len(content_ids),
        "version_count": total_versions,
        "total_size_bytes": total_size,
        "formats": formats,
    }

# Usage
summary = summarize_storage(storage)
print(f"Content items: {summary['content_count']}")
print(f"Total versions: {summary['version_count']}")
print(f"Total size: {summary['total_size_bytes'] / 1024:.2f} KB")
print(f"Formats: {summary['formats']}")
```

### Export Content List

```python
import json

def export_content_list(storage, output_file):
    """Export content list to JSON."""
    catalog = build_catalog(storage)

    with open(output_file, "w") as f:
        json.dump(catalog, f, indent=2)

    print(f"Exported catalog to {output_file}")

# Usage
export_content_list(storage, "content_catalog.json")
```

---

## Best Practices

### Do ✅

1. **Cache content list for repeated access**
   ```python
   # Cache list to avoid repeated filesystem scans
   content_list = storage.list_content()
   for content_id in content_list:
       # Use cached list
       process(content_id)
   ```

2. **Use batch operations for multiple retrievals**
   ```python
   # Retrieve multiple items at once
   contents = batch_retrieve(storage, ["api-docs", "readme"])
   ```

3. **Check existence before retrieving**
   ```python
   if "api-docs" in storage.list_content():
       content = storage.retrieve("api-docs")
   ```

### Don't ❌

1. **Don't retrieve all content unnecessarily**
   ```python
   # ❌ Bad: Load everything into memory
   all_content = {id: storage.retrieve(id) for id in storage.list_content()}

   # ✅ Good: Retrieve only what you need
   content = storage.retrieve("api-docs")
   ```

2. **Don't ignore errors**
   ```python
   # ❌ Bad: Silent failure
   content = storage.retrieve("might-not-exist")

   # ✅ Good: Handle errors
   try:
       content = storage.retrieve("might-not-exist")
   except FileNotFoundError:
       # Handle missing content
       content = generate_default()
   ```

---

## Summary

**Key operations**:
- **List**: `list_content()` for all IDs
- **Retrieve**: `retrieve(id)` for latest version
- **Filter**: Custom functions by date, format, metadata
- **Batch**: Retrieve multiple items efficiently
- **Metadata**: Inspect version info and provenance

**Common patterns**:
1. List → Filter → Retrieve
2. Batch retrieval for multiple items
3. Build catalog with metadata
4. Paginate large result sets

---

## Related Documentation

- [Understand Versioning](understand-versioning.md) - Version management
- [Manage Ephemeral Storage](manage-ephemeral-storage.md) - Storage basics
- [Clean Up Storage](cleanup-storage.md) - Cleanup operations

---

**Last Updated**: 2025-10-21 | **Sprint**: 4 - Storage Documentation
